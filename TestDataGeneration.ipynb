{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestDataGeneration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZKOEYF9w5UeeB0gxReEpi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonycccccc/tony.github.io/blob/main/TestDataGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40kFjSWG4BDm",
        "outputId": "c0ec5a99-0b4a-4e4d-80dc-c831f06d98b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "# load matrix from files\n",
        "all_query_files = glob.glob(\"/content/drive/MyDrive/models/transformer/logging_query*.txt\")\n",
        "all_key_files = glob.glob(\"/content/drive/MyDrive/models/transformer/logging_key*.txt\")\n",
        "all_value_files = glob.glob(\"/content/drive/MyDrive/models/transformer/logging_value*.txt\")\n",
        "all_bias_files = glob.glob(\"/content/drive/MyDrive/models/transformer/logging_bias*.txt\")\n",
        "query_matrix = []\n",
        "key_matrix = []\n",
        "value_matrix = []\n",
        "bias_matrix=[]\n",
        "for file in all_query_files:\n",
        "    query_file = tf.io.read_file(file)\n",
        "    query = tf.io.parse_tensor(query_file, out_type=tf.float32)\n",
        "    query_matrix.append(query)\n",
        "for file in all_key_files:\n",
        "    key_file = tf.io.read_file(file)\n",
        "    key = tf.io.parse_tensor(key_file, out_type=tf.float32)\n",
        "    key_matrix.append(key)\n",
        "for file in all_value_files:\n",
        "    value_file = tf.io.read_file(file)\n",
        "    value = tf.io.parse_tensor(value_file, out_type=tf.float32)\n",
        "    value_matrix.append(value)\n",
        "for file in all_bias_files:\n",
        "    bias_file = tf.io.read_file(file)\n",
        "    bias = tf.io.parse_tensor(bias_file, out_type=tf.float32)\n",
        "    bias_matrix.append(bias)"
      ],
      "metadata": {
        "id": "TtH_tGTL4Lhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_matrix = np.concatenate(query_matrix)\n",
        "key_matrix = np.concatenate(key_matrix)\n",
        "value_matrix = np.concatenate(value_matrix)"
      ],
      "metadata": {
        "id": "KggxV4eC6peM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Test Matrix with shape 1 * n * 16 * 64\n",
        "# Set matrix_size to 2k, 4k, 8k, 16k, 32k, and 64k\n",
        "matrix_size = 256 * 1024\n",
        "data_query = []\n",
        "data_key = []\n",
        "data_value = []\n",
        "for i in range(matrix_size // 64):\n",
        "  idx = np.random.randint(0, 576)\n",
        "  data_query.append(query_matrix[idx, :, :, :])\n",
        "  data_key.append(key_matrix[idx, :, :, :])\n",
        "  data_value.append(value_matrix[idx, :, :, :])\n",
        "query_matrix = np.concatenate(data_query)[None, :, :, :]\n",
        "key_matrix = np.concatenate(data_key)[None, :, :, :]\n",
        "value_matrix = np.concatenate(data_value)[None, :, :, :]"
      ],
      "metadata": {
        "id": "lazF4al94MPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/models/transformer/Test/\"\n",
        "string0 = tf.io.serialize_tensor(query_matrix)\n",
        "tf.io.write_file(path+\"logging_query2k.txt\", string0)\n",
        "string1 = tf.io.serialize_tensor(key_matrix)\n",
        "tf.io.write_file(path+\"logging_key2k.txt\", string1)\n",
        "string2 = tf.io.serialize_tensor(value_matrix)\n",
        "tf.io.write_file(path+\"logging_value2k.txt\", string2)\n",
        "string3 = tf.io.serialize_tensor(bias_matrix[0])\n",
        "tf.io.write_file(path+\"logging_bias2k.txt\", string3)"
      ],
      "metadata": {
        "id": "E4hxiMJg4hDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_matrix.shape"
      ],
      "metadata": {
        "id": "OQVGcOpt8RJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbaba8d-d0bf-4c99-a459-6e3582910aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 262144, 16, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cyiZARMHD7hE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}